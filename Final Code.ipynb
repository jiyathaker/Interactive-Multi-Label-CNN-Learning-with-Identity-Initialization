{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBC05e9S08K3",
        "outputId": "c09db721-9dc9-4b5d-efe7-f62dc6e017b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics import average_precision_score\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Sh9aCp8s139C"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "dataset_path = '/content/drive/MyDrive/CUB_200_2011/CUB_200_2011/images'\n",
        "output_path = '/content/drive/MyDrive/CUB_200_2011/limited_data'\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# Preprocessing pipeline\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "FKpU4bGm0ix-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess a maximum of 1,000 images\n",
        "all_images = []\n",
        "all_labels = []\n",
        "max_images = 1000\n",
        "image_counter = 0\n",
        "\n",
        "for class_folder in os.listdir(dataset_path):\n",
        "    class_path = os.path.join(dataset_path, class_folder)\n",
        "    if os.path.isdir(class_path):\n",
        "        label = int(class_folder.split('.')[0]) - 1  # Convert to 0-based index\n",
        "        images = os.listdir(class_path)\n",
        "        for img_file in images:\n",
        "            img_path = os.path.join(class_path, img_file)\n",
        "            try:\n",
        "                img = Image.open(img_path).convert(\"RGB\")\n",
        "                img_tensor = transform(img)\n",
        "                all_images.append(img_tensor)\n",
        "                all_labels.append(label)\n",
        "                image_counter += 1\n",
        "                if image_counter >= max_images:\n",
        "                    break\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {img_path}: {e}\")\n",
        "        if image_counter >= max_images:\n",
        "            break\n",
        "\n",
        "# Save preprocessed data\n",
        "all_images = torch.stack(all_images)\n",
        "all_labels = torch.tensor(all_labels)\n",
        "torch.save({'images': all_images, 'labels': all_labels}, os.path.join(output_path, 'limited_data.pt'))\n",
        "\n",
        "print(f\"Dataset preprocessed. Total images: {len(all_images)}. Saved at {output_path}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0wNeZhO0qNV",
        "outputId": "b5d71a2e-98d3-42f1-cf94-bf0fff39bc6e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset preprocessed. Total images: 1000. Saved at /content/drive/MyDrive/CUB_200_2011/limited_data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load preprocessed data\n",
        "data = torch.load('/content/drive/MyDrive/CUB_200_2011/limited_data/limited_data.pt')\n",
        "images, labels = data['images'], data['labels']\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "def to_one_hot(labels, num_classes):\n",
        "    return torch.eye(num_classes)[labels]\n",
        "\n",
        "num_classes = 200  # Total number of classes\n",
        "labels_one_hot = to_one_hot(labels, num_classes)\n",
        "\n",
        "# Create TensorDataset\n",
        "dataset = TensorDataset(images, labels_one_hot)\n",
        "\n",
        "# Split into train and test sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "print(f\"Dataset split: {train_size} training samples, {test_size} testing samples.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AkRacZj0vwe",
        "outputId": "4f947b85-4a44-4da8-d06c-5ac9911ae867"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-d1d4e9c683bc>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load('/content/drive/MyDrive/CUB_200_2011/limited_data/limited_data.pt')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split: 800 training samples, 200 testing samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the multi-label classification model\n",
        "class MultiLabelCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(MultiLabelCNN, self).__init__()\n",
        "        self.backbone = models.resnet50(pretrained=True)\n",
        "        self.backbone.fc = nn.Sequential(\n",
        "            nn.Linear(self.backbone.fc.in_features, num_classes),\n",
        "            nn.Sigmoid()  # Sigmoid for multi-label output\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "# Initialize the model\n",
        "model = MultiLabelCNN(num_classes)\n",
        "print(\"Model initialized.\")\n",
        "\n",
        "# Initialize label similarity graph (identity matrix)\n",
        "label_similarity_graph = np.eye(num_classes)\n",
        "label_similarity_graph = torch.tensor(label_similarity_graph, dtype=torch.float32)\n",
        "\n",
        "print(\"Initialized label similarity graph (identity matrix).\")\n",
        "\n",
        "# Collaborative loss function\n",
        "def collaborative_loss(predictions, targets, similarity_graph, lambda_graph=0.01):\n",
        "    bce_loss = nn.BCELoss()(predictions, targets)\n",
        "    graph_term = torch.sum(similarity_graph * torch.mm(predictions.T, predictions)) / predictions.size(0)\n",
        "    return bce_loss + lambda_graph * graph_term\n",
        "\n",
        "# Refine the similarity graph\n",
        "def refine_similarity_graph(predictions, current_graph, alpha=0.9):\n",
        "    co_occurrence = torch.mm(predictions.T, predictions) / predictions.size(0)\n",
        "    updated_graph = alpha * current_graph + (1 - alpha) * co_occurrence\n",
        "    return updated_graph\n",
        "\n",
        "# Training loop\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 10\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    for imgs, lbls in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = collaborative_loss(outputs, lbls.float(), label_similarity_graph)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # Refine the similarity graph\n",
        "    with torch.no_grad():\n",
        "        all_predictions = []\n",
        "        for imgs, _ in train_loader:\n",
        "            outputs = model(imgs)\n",
        "            all_predictions.append(outputs)\n",
        "        all_predictions = torch.cat(all_predictions)\n",
        "        label_similarity_graph = refine_similarity_graph(all_predictions, label_similarity_graph)\n",
        "\n",
        "    print(f\"Label similarity graph refined at epoch {epoch+1}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhT18XuA02Be",
        "outputId": "7afb17d8-a50f-4e79-f7e1-8f443e9f32d4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model initialized.\n",
            "Initialized label similarity graph (identity matrix).\n",
            "Epoch [1/10], Loss: 0.0625\n",
            "Label similarity graph refined at epoch 1.\n",
            "Epoch [2/10], Loss: 0.0157\n",
            "Label similarity graph refined at epoch 2.\n",
            "Epoch [3/10], Loss: 0.0135\n",
            "Label similarity graph refined at epoch 3.\n",
            "Epoch [4/10], Loss: 0.0123\n",
            "Label similarity graph refined at epoch 4.\n",
            "Epoch [5/10], Loss: 0.0102\n",
            "Label similarity graph refined at epoch 5.\n",
            "Epoch [6/10], Loss: 0.0096\n",
            "Label similarity graph refined at epoch 6.\n",
            "Epoch [7/10], Loss: 0.0078\n",
            "Label similarity graph refined at epoch 7.\n",
            "Epoch [8/10], Loss: 0.0071\n",
            "Label similarity graph refined at epoch 8.\n",
            "Epoch [9/10], Loss: 0.0068\n",
            "Label similarity graph refined at epoch 9.\n",
            "Epoch [10/10], Loss: 0.0067\n",
            "Label similarity graph refined at epoch 10.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    \"\"\"\n",
        "    Evaluates the model using Mean Average Precision (mAP).\n",
        "    Filters out classes with no positive samples in the ground truth.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    # Collect all predictions and ground truth labels\n",
        "    with torch.no_grad():\n",
        "        for imgs, lbls in test_loader:\n",
        "            outputs = model(imgs)  # Model predictions\n",
        "            all_predictions.append(outputs.numpy())\n",
        "            all_labels.append(lbls.numpy())\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    all_predictions = np.concatenate(all_predictions)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "\n",
        "    # Identify valid classes (at least one positive sample in y_true)\n",
        "    valid_classes = (all_labels.sum(axis=0) > 0).nonzero()[0]\n",
        "    if len(valid_classes) == 0:\n",
        "        print(\"No valid classes with positive samples found.\")\n",
        "        return 0.0\n",
        "\n",
        "    # Filter valid classes\n",
        "    all_labels_filtered = all_labels[:, valid_classes]\n",
        "    all_predictions_filtered = all_predictions[:, valid_classes]\n",
        "\n",
        "    # Compute mAP\n",
        "    mAP = average_precision_score(all_labels_filtered, all_predictions_filtered, average=\"macro\")\n",
        "    print(f\"Valid Classes: {len(valid_classes)} / {all_labels.shape[1]}\")\n",
        "    print(f\"Mean Average Precision (mAP): {mAP:.4f}\")\n",
        "    return mAP\n",
        "\n",
        "# Evaluate the model\n",
        "mAP_score = evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgaUvjsh1QLW",
        "outputId": "13951940-c0b3-4181-ff7c-3e2d5f32e4d8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Classes: 18 / 200\n",
            "Mean Average Precision (mAP): 0.8214\n"
          ]
        }
      ]
    }
  ]
}